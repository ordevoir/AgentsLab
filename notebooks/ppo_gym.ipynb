{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d7a86d02",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Общее конфигурирование\n",
        "from agentslab.utils.device import resolve_device\n",
        "from agentslab.utils.seeding import set_global_seed\n",
        "from pathlib import Path\n",
        "\n",
        "device = resolve_device()\n",
        "print('Device:', device)\n",
        " \n",
        "seed = 42\n",
        "set_global_seed(seed, deterministic=True)\n",
        "\n",
        "ROOT = Path('..').resolve()\n",
        "ALGO_NAME, ENV_NAME = \"ppo\", \"pendulum\"\n",
        "ENV_ID = \"InvertedDoublePendulum-v4\"\n",
        "# ENV_ID = \"CartPole-v1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8a620aba",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Log dir: C:\\Users\\werna\\Documents\\GitHub\\AgentsLab\\logs\\ppo_gym_demo_20250821-180714\n",
            "Checkpoint dir: C:\\Users\\werna\\Documents\\GitHub\\AgentsLab\\checkpoints\\ppo_InvertedDoublePendulum-v4_demo_20250821-180714\n"
          ]
        }
      ],
      "source": [
        "# DRAFT\n",
        "\n",
        "from datetime import datetime\n",
        "from agentslab.utils.checkpointers import CheckpointInfo, save_checkpoint, load_checkpoint\n",
        "\n",
        "run_name = f\"ppo_gym_demo_{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
        "\n",
        "\n",
        "LOGS_ROOT = (ROOT / 'logs').resolve()\n",
        "CKPT_ROOT = (ROOT / 'checkpoints').resolve()\n",
        "LOGS_ROOT.mkdir(exist_ok=True)\n",
        "CKPT_ROOT.mkdir(exist_ok=True)\n",
        "\n",
        "log_dir = LOGS_ROOT / run_name\n",
        "ckpt_info = CheckpointInfo(algo='ppo', env_id='InvertedDoublePendulum-v4', run_name='demo', dir_root=str(CKPT_ROOT))\n",
        "run_ckpt_dir = ckpt_info.make_run_dir()\n",
        "\n",
        "from agentslab.utils.logger import CSVLogger\n",
        "from agentslab.utils.curves import plot_training_curves\n",
        "\n",
        "\n",
        "logger = CSVLogger(str(log_dir))\n",
        "\n",
        "print('Log dir:', log_dir)\n",
        "print('Checkpoint dir:', run_ckpt_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d54dd996",
      "metadata": {},
      "source": [
        "# Создание среды"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6d131b0e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92m2025-08-21 18:07:16,077 [torchrl][INFO]\u001b[0m    check_env_specs succeeded!\u001b[92m [END]\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from agentslab.envs.gym_factory import GymEnvConfig, make_gym_env\n",
        "from torchrl.envs.utils import check_env_specs\n",
        "\n",
        "env_cfg = GymEnvConfig(env_id=ENV_ID, render_mode=None, device=device, seed=seed)\n",
        "env = make_gym_env(env_cfg)\n",
        "check_env_specs(env)\n",
        "\n",
        "# from agentslab.utils.specs import print_specs\n",
        "# print_specs(env)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35c427be",
      "metadata": {},
      "source": [
        "# Создание актора и критика"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d3824baf",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ValueOperator(\n",
              "    module=Sequential(\n",
              "      (0): Linear(in_features=11, out_features=256, bias=True)\n",
              "      (1): Tanh()\n",
              "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (3): Tanh()\n",
              "      (4): Linear(in_features=256, out_features=1, bias=True)\n",
              "    ),\n",
              "    device=cpu,\n",
              "    in_keys=['observation'],\n",
              "    out_keys=['state_value'])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from agentslab.modules.networks import MLPConfig, build_mlp\n",
        "from agentslab.modules.policy import build_stochastic_actor\n",
        "from torchrl.modules import ValueOperator\n",
        "\n",
        "# Достаём размерности\n",
        "obs_dim = env.observation_spec[\"observation\"].shape[-1]\n",
        "act_dim = env.action_spec.shape[-1]\n",
        "\n",
        "mlp_cfg = MLPConfig(\n",
        "        in_dim = obs_dim, \n",
        "        out_dim = 2*act_dim,\n",
        "        hidden_sizes = (256, 256),\n",
        "        activation = \"tanh\",\n",
        "        layer_norm = False\n",
        ")\n",
        "\n",
        "actor_network = build_mlp(mlp_cfg)\n",
        "actor = build_stochastic_actor(actor_network, env.action_spec)\n",
        "\n",
        "mlp_cfg.out_dim = act_dim\n",
        "critic_network = build_mlp(mlp_cfg)\n",
        "critic = ValueOperator(module=critic_network, in_keys=[\"observation\"])\n",
        "critic"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ebea77ec",
      "metadata": {},
      "source": [
        "# Collector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6a9cdc46",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchrl.collectors import SyncDataCollector\n",
        "from torchrl.data.replay_buffers import ReplayBuffer\n",
        "from torchrl.data.replay_buffers.samplers import SamplerWithoutReplacement\n",
        "from torchrl.data.replay_buffers.storages import LazyTensorStorage\n",
        "\n",
        "frames_per_batch = 1000\n",
        "# For a complete training, bring the number of frames up to 1M\n",
        "total_frames = 10_000\n",
        "\n",
        "collector = SyncDataCollector(\n",
        "    create_env_fn=env,\n",
        "    policy=actor,\n",
        "    frames_per_batch=frames_per_batch,\n",
        "    total_frames=total_frames,\n",
        "    split_trajs=False,\n",
        "    device=device,\n",
        ")\n",
        "replay_buffer = ReplayBuffer(\n",
        "    storage=LazyTensorStorage(max_size=frames_per_batch),\n",
        "    sampler=SamplerWithoutReplacement(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c8859fad",
      "metadata": {},
      "source": [
        "# Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e45ce2a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchrl.objectives import ClipPPOLoss\n",
        "from torchrl.objectives.value import GAE\n",
        "import torch\n",
        "\n",
        "gamma = 0.99\n",
        "lmbda = 0.95\n",
        "\n",
        "advantage_module = GAE(\n",
        "    gamma=gamma, lmbda=lmbda, value_network=critic, average_gae=True\n",
        ")\n",
        "\n",
        "clip_epsilon = (\n",
        "    0.2  # clip value for PPO loss: see the equation in the intro for more context.\n",
        ")\n",
        "entropy_eps = 1e-4\n",
        "\n",
        "loss_module = ClipPPOLoss(\n",
        "    actor_network=actor,\n",
        "    critic_network=critic,\n",
        "    clip_epsilon=clip_epsilon,\n",
        "    entropy_bonus=bool(entropy_eps),\n",
        "    entropy_coeff=entropy_eps,\n",
        "    # these keys match by default but we set this for completeness\n",
        "    critic_coeff=1.0,\n",
        "    loss_critic_type=\"smooth_l1\",\n",
        ")\n",
        "\n",
        "lr = 3e-4\n",
        "\n",
        "optim = torch.optim.Adam(loss_module.parameters(), lr)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer=optim, \n",
        "    T_max=total_frames // frames_per_batch, \n",
        "    eta_min=0.0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cfa17c6",
      "metadata": {},
      "source": [
        "\n",
        "# Logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "399b9375",
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_logfile(log_dir=\"logs\", name=None, run_name=None, fieldnames=None):\n",
        "    import os, csv, time\n",
        "    os.makedirs(log_dir, exist_ok=True)\n",
        "    ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
        "    run_name = run_name or f\"run_{ts}\"\n",
        "    if name:\n",
        "        run_name = name + \"_\" + run_name\n",
        "    log_path = os.path.join(log_dir, f\"{run_name}.csv\")\n",
        "    fieldnames = fieldnames or [\"step\",\"metric\",\"value\"]  # дефолт\n",
        "    with open(log_path, \"w\", newline=\"\") as f:\n",
        "        csv.DictWriter(f, fieldnames=fieldnames).writeheader()\n",
        "    return log_path\n",
        "\n",
        "def log_row(log_path, fieldnames, row: dict):\n",
        "    import csv\n",
        "    with open(log_path, \"a\", newline=\"\") as f:\n",
        "        csv.DictWriter(f, fieldnames=fieldnames).writerow(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "3967ac3e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'logs\\\\ppo_run_20250821-180716.csv'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fieldnames = [\n",
        "    \"batch_idx\",\n",
        "    \"frames\",\n",
        "    \"reward_mean\",\n",
        "    \"reward_init\",\n",
        "    \"step_count_max\",\n",
        "    \"lr\",\n",
        "    \"eval_reward_mean\",\n",
        "    \"eval_reward_sum\",\n",
        "    \"eval_step_count\",\n",
        "]\n",
        "\n",
        "log_path = prepare_logfile(fieldnames=fieldnames, name=\"ppo\")\n",
        "log_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "728107a0",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "f4af448a",
      "metadata": {},
      "source": [
        "## Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "7abe3f58",
      "metadata": {},
      "outputs": [],
      "source": [
        "# from torchrl.envs.utils import ExplorationType, set_exploration_type\n",
        "# import torch\n",
        "\n",
        "# from typing import Dict\n",
        "# @torch.no_grad()\n",
        "# def eval_policy(env, actor, n_steps: int = 1000) -> Dict[str, float]:\n",
        "#     \"\"\"\n",
        "#     Выполняет детерминированный rollout политики и возвращает метрики.\n",
        "#     \"\"\"\n",
        "#     # На время оценки выключаем стохастику действий\n",
        "#     actor_was_training = actor.training\n",
        "#     actor.eval()\n",
        "#     with set_exploration_type(ExplorationType.DETERMINISTIC):\n",
        "#         eval_rollout = env.rollout(n_steps, actor)\n",
        "#         result = {\n",
        "#             \"eval_reward_mean\": eval_rollout[\"next\", \"reward\"].mean().item(),\n",
        "#             \"eval_reward_sum\": eval_rollout[\"next\", \"reward\"].sum().item(),\n",
        "#             \"eval_step_count\": eval_rollout[\"step_count\"].max().item(),\n",
        "#         }\n",
        "#         del eval_rollout\n",
        "#     if actor_was_training:\n",
        "#         actor.train()\n",
        "#     return result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "192792e9",
      "metadata": {},
      "source": [
        "# Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "785ade9f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0908f367e7e49099305a52631e81afa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "eval:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but got mat1 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_addmm)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[31mRuntimeError\u001b[39m: TensorDictModule failed with operation\n    Sequential(\n      (0): Sequential(\n        (0): Linear(in_features=11, out_features=256, bias=True)\n        (1): Tanh()\n        (2): Linear(in_features=256, out_features=256, bias=True)\n        (3): Tanh()\n        (4): Linear(in_features=256, out_features=2, bias=True)\n      )\n      (1): NormalParamExtractor(\n        (scale_mapping): biased_softplus()\n      )\n    )\n    in_keys=['observation']\n    out_keys=['loc', 'scale'].",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magentslab\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunners\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m eval_policy\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43meval_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisodes\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\GitHub\\AgentsLab\\src\\agentslab\\runners\\evals.py:54\u001b[39m, in \u001b[36meval_policy\u001b[39m\u001b[34m(env, policy, steps, episodes, deterministic, progress, desc, leave)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_exploration_type(expl_type):\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m         td = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;66;03m# Возврат: суммируем по времени и усредняем по batch-осям (если есть)\u001b[39;00m\n\u001b[32m     57\u001b[39m     rew = td.get((\u001b[33m\"\u001b[39m\u001b[33mnext\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mreward\u001b[39m\u001b[33m\"\u001b[39m))  \u001b[38;5;66;03m# shape ~ [T, *B, ...]\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torchrl\\envs\\common.py:3377\u001b[39m, in \u001b[36mEnvBase.rollout\u001b[39m\u001b[34m(self, max_steps, policy, callback, auto_reset, auto_cast_to_device, break_when_any_done, break_when_all_done, return_contiguous, tensordict, set_truncated, out, trust_policy)\u001b[39m\n\u001b[32m   3367\u001b[39m kwargs = {\n\u001b[32m   3368\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtensordict\u001b[39m\u001b[33m\"\u001b[39m: tensordict,\n\u001b[32m   3369\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mauto_cast_to_device\u001b[39m\u001b[33m\"\u001b[39m: auto_cast_to_device,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3374\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcallback\u001b[39m\u001b[33m\"\u001b[39m: callback,\n\u001b[32m   3375\u001b[39m }\n\u001b[32m   3376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m break_when_any_done \u001b[38;5;129;01mor\u001b[39;00m break_when_all_done:\n\u001b[32m-> \u001b[39m\u001b[32m3377\u001b[39m     tensordicts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_rollout_stop_early\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3378\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbreak_when_all_done\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbreak_when_all_done\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbreak_when_any_done\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbreak_when_any_done\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3380\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3381\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3382\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3383\u001b[39m     tensordicts = \u001b[38;5;28mself\u001b[39m._rollout_nonstop(**kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torchrl\\envs\\common.py:3511\u001b[39m, in \u001b[36mEnvBase._rollout_stop_early\u001b[39m\u001b[34m(self, break_when_any_done, break_when_all_done, tensordict, auto_cast_to_device, max_steps, policy, policy_device, env_device, callback)\u001b[39m\n\u001b[32m   3509\u001b[39m         tensordict.clear_device_()\n\u001b[32m   3510\u001b[39m \u001b[38;5;66;03m# In case policy(..) does not modify in-place - no-op for TensorDict and related\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3511\u001b[39m tensordict.update(\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   3512\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m auto_cast_to_device:\n\u001b[32m   3513\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m env_device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\utils.py:372\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28mself\u001b[39m.prev = _skip_existing.get_mode()\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    374\u001b[39m     _skip_existing.set_mode(\u001b[38;5;28mself\u001b[39m.prev)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\probabilistic.py:1348\u001b[39m, in \u001b[36mProbabilisticTensorDictSequential.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m   1344\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1345\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed while executing module \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_num_or_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Scroll up for more info.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1346\u001b[39m             ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1348\u001b[39m     tensordict_exec = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_dist_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict_exec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1349\u001b[39m     tensordict_exec = \u001b[38;5;28mself\u001b[39m._last_module(\n\u001b[32m   1350\u001b[39m         tensordict_exec, _requires_sample=\u001b[38;5;28mself\u001b[39m._requires_sample\n\u001b[32m   1351\u001b[39m     )\n\u001b[32m   1353\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.inplace \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\probabilistic.py:1100\u001b[39m, in \u001b[36mProbabilisticTensorDictSequential.get_dist_params\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m   1098\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCould not find a default interaction in the modules.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1099\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_interaction_type(\u001b[38;5;28mtype\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1100\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\utils.py:372\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28mself\u001b[39m.prev = _skip_existing.get_mode()\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    374\u001b[39m     _skip_existing.set_mode(\u001b[38;5;28mself\u001b[39m.prev)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\sequence.py:627\u001b[39m, in \u001b[36mTensorDictSequential.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, **kwargs)\u001b[39m\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._module_iter():\n\u001b[32m    626\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m         tensordict_exec = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_exec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    631\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m _has_py311_or_greater:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\sequence.py:573\u001b[39m, in \u001b[36mTensorDictSequential._run_module\u001b[39m\u001b[34m(self, module, tensordict, **kwargs)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_module\u001b[39m(\n\u001b[32m    565\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    566\u001b[39m     module: TensorDictModuleBase,\n\u001b[32m    567\u001b[39m     tensordict: TensorDictBase,\n\u001b[32m    568\u001b[39m     **kwargs: Any,\n\u001b[32m    569\u001b[39m ) -> Any:\n\u001b[32m    570\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partial_tolerant \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m    571\u001b[39m         key \u001b[38;5;129;01min\u001b[39;00m tensordict.keys(include_nested=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.in_keys\n\u001b[32m    572\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m         tensordict = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    574\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partial_tolerant \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensordict, LazyStackedTensorDict):\n\u001b[32m    575\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m sub_td \u001b[38;5;129;01min\u001b[39;00m tensordict.tensordicts:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\utils.py:372\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28mself\u001b[39m.prev = _skip_existing.get_mode()\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    374\u001b[39m     _skip_existing.set_mode(\u001b[38;5;28mself\u001b[39m.prev)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\common.py:1218\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1216\u001b[39m in_keys = indent(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33min_keys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.in_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[32m4\u001b[39m * \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1217\u001b[39m out_keys = indent(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mout_keys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.out_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[32m4\u001b[39m * \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1218\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1219\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTensorDictModule failed with operation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00min_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mout_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1220\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\common.py:1190\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1184\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m   1185\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSome tensors that are necessary for the module call may \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1186\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnot have not been found in the input tensordict: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1187\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mthe following inputs are None: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnone_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1188\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1189\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1190\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors_out, (\u001b[38;5;28mdict\u001b[39m, TensorDictBase)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m   1192\u001b[39m     key \u001b[38;5;129;01min\u001b[39;00m tensors_out \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.out_keys\n\u001b[32m   1193\u001b[39m ):\n\u001b[32m   1194\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors_out, \u001b[38;5;28mdict\u001b[39m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\common.py:1174\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1165\u001b[39m     tensors = \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m   1166\u001b[39m         tensordict._get_tuple_maybe_non_tensor(\n\u001b[32m   1167\u001b[39m             _unravel_key_to_tuple(in_key),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1171\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m in_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.in_keys\n\u001b[32m   1172\u001b[39m     )\n\u001b[32m   1173\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1174\u001b[39m     tensors_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1175\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tensors_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1176\u001b[39m         tensors_out = ()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\common.py:1133\u001b[39m, in \u001b[36mTensorDictModule._call_module\u001b[39m\u001b[34m(self, tensors, **kwargs)\u001b[39m\n\u001b[32m   1131\u001b[39m kwargs.update(\u001b[38;5;28mself\u001b[39m.method_kwargs)\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1135\u001b[39m     out = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.module, \u001b[38;5;28mself\u001b[39m.method)(*tensors, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but got mat1 is on cuda:0, different from other tensors on cpu (when checking argument in method wrapper_CUDA_addmm)",
            "Failed while executing module '0'."
          ]
        }
      ],
      "source": [
        "from agentslab.runners.evals import eval_policy\n",
        "\n",
        "eval_policy(env, actor, episodes=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c8c21a2f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10000 [00:00<?, ?it/s]"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but got mat2 is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA_mm)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[31mRuntimeError\u001b[39m: TensorDictModule failed with operation\n    Sequential(\n      (0): Linear(in_features=11, out_features=256, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=256, out_features=256, bias=True)\n      (3): Tanh()\n      (4): Linear(in_features=256, out_features=1, bias=True)\n    )\n    in_keys=['observation']\n    out_keys=['state_value'].",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 142\u001b[39m\n\u001b[32m    131\u001b[39m LogValidationReward(\n\u001b[32m    132\u001b[39m     record_interval=optim_steps_per_batch * \u001b[32m2\u001b[39m,\n\u001b[32m    133\u001b[39m     record_frames=frames_per_batch,         \u001b[38;5;66;03m# ~ несколько эпизодов; можно увеличить\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    138\u001b[39m     log_pbar=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    139\u001b[39m ).register(trainer)  \u001b[38;5;66;03m# :contentReference[oaicite:6]{index=6}\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[38;5;66;03m# --- поехали ---\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torchrl\\trainers\\trainers.py:453\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    450\u001b[39m     \u001b[38;5;28mself\u001b[39m._pbar_str = {}\n\u001b[32m    452\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.collector:\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m     batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_batch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    454\u001b[39m     current_frames = (\n\u001b[32m    455\u001b[39m         batch.get((\u001b[33m\"\u001b[39m\u001b[33mcollector\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmask\u001b[39m\u001b[33m\"\u001b[39m), torch.tensor(batch.numel()))\n\u001b[32m    456\u001b[39m         .sum()\n\u001b[32m    457\u001b[39m         .item()\n\u001b[32m    458\u001b[39m         * \u001b[38;5;28mself\u001b[39m.frame_skip\n\u001b[32m    459\u001b[39m     )\n\u001b[32m    460\u001b[39m     \u001b[38;5;28mself\u001b[39m.collected_frames += current_frames\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torchrl\\trainers\\trainers.py:391\u001b[39m, in \u001b[36mTrainer._process_batch_hook\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_process_batch_hook\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: TensorDictBase) -> TensorDictBase:\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m op, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._batch_process_ops:\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m         out = \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    392\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, TensorDictBase):\n\u001b[32m    393\u001b[39m             batch = out\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 80\u001b[39m, in \u001b[36mPPOEpochAdvantage.__call__\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m     78\u001b[39m     \u001b[38;5;28mself\u001b[39m._batch = batch\n\u001b[32m     79\u001b[39m     \u001b[38;5;28mself\u001b[39m._k = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_batch\u001b[49m\u001b[43m)\u001b[49m     \u001b[38;5;66;03m# первичный расчёт\u001b[39;00m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._batch\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:      \u001b[38;5;66;03m# пришёл post_optim\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torchrl\\objectives\\value\\advantages.py:79\u001b[39m, in \u001b[36m_self_set_skip_existing.<locals>.new_func\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_skip_existing(\u001b[38;5;28mself\u001b[39m.skip_existing):\n\u001b[32m     78\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torchrl\\objectives\\value\\advantages.py:68\u001b[39m, in \u001b[36m_self_set_grad_enabled.<locals>.new_fun\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fun)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.differentiable):\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torchrl\\objectives\\value\\advantages.py:1491\u001b[39m, in \u001b[36mGAE.forward\u001b[39m\u001b[34m(self, tensordict, params, target_params, time_dim)\u001b[39m\n\u001b[32m   1484\u001b[39m             target_params = params.clone(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m hold_out_net(\u001b[38;5;28mself\u001b[39m.value_network) \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1486\u001b[39m         params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m target_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1487\u001b[39m     ) \u001b[38;5;28;01melse\u001b[39;00m nullcontext():\n\u001b[32m   1488\u001b[39m         \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[32m   1489\u001b[39m         \u001b[38;5;66;03m# we may still need to pass gradient, but we don't want to assign grads to\u001b[39;00m\n\u001b[32m   1490\u001b[39m         \u001b[38;5;66;03m# value net params\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m         value, next_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_value_nets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1493\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1494\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnext_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1495\u001b[39m \u001b[43m            \u001b[49m\u001b[43msingle_call\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshifted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1496\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalue_key\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtensor_keys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1497\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdetach_next\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1498\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvmap_randomness\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvmap_randomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1499\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1500\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1501\u001b[39m     value = tensordict.get(\u001b[38;5;28mself\u001b[39m.tensor_keys.value)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torchrl\\objectives\\value\\advantages.py:543\u001b[39m, in \u001b[36mValueEstimatorBase._call_value_nets\u001b[39m\u001b[34m(self, data, params, next_params, single_call, value_key, detach_next, vmap_randomness, value_net)\u001b[39m\n\u001b[32m    536\u001b[39m     data_out = _vmap_func(\n\u001b[32m    537\u001b[39m         value_net,\n\u001b[32m    538\u001b[39m         (\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m),\n\u001b[32m    539\u001b[39m         randomness=vmap_randomness,\n\u001b[32m    540\u001b[39m         pseudo_vmap=\u001b[38;5;28mself\u001b[39m.deactivate_vmap,\n\u001b[32m    541\u001b[39m     )(data_in, params_stack)\n\u001b[32m    542\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.deactivate_vmap:\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m     data_out = \u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvmap_randomness\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    545\u001b[39m     data_out = _pseudo_vmap(value_net, (\u001b[32m0\u001b[39m,), randomness=vmap_randomness)(\n\u001b[32m    546\u001b[39m         data_in\n\u001b[32m    547\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\_functorch\\apis.py:202\u001b[39m, in \u001b[36mvmap.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\_functorch\\vmap.py:334\u001b[39m, in \u001b[36mvmap_impl\u001b[39m\u001b[34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[39m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _chunked_vmap(\n\u001b[32m    324\u001b[39m         func,\n\u001b[32m    325\u001b[39m         flat_in_dims,\n\u001b[32m   (...)\u001b[39m\u001b[32m    330\u001b[39m         **kwargs,\n\u001b[32m    331\u001b[39m     )\n\u001b[32m    333\u001b[39m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m334\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\_functorch\\vmap.py:484\u001b[39m, in \u001b[36m_flat_vmap\u001b[39m\u001b[34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[39m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[32m    481\u001b[39m     batched_inputs = _create_batched_inputs(\n\u001b[32m    482\u001b[39m         flat_in_dims, flat_args, vmap_level, args_spec\n\u001b[32m    483\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m     batched_outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\common.py:328\u001b[39m, in \u001b[36mdispatch.__call__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) == \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m func(tensordict, *args, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\utils.py:372\u001b[39m, in \u001b[36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[39m\u001b[34m(_self, tensordict, *args, **kwargs)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28mself\u001b[39m.prev = _skip_existing.get_mode()\n\u001b[32m    371\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    374\u001b[39m     _skip_existing.set_mode(\u001b[38;5;28mself\u001b[39m.prev)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\common.py:1218\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1216\u001b[39m in_keys = indent(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33min_keys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.in_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[32m4\u001b[39m * \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1217\u001b[39m out_keys = indent(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mout_keys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.out_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[32m4\u001b[39m * \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1218\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1219\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTensorDictModule failed with operation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00min_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mout_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1220\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\common.py:1190\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1184\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m   1185\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSome tensors that are necessary for the module call may \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1186\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnot have not been found in the input tensordict: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1187\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mthe following inputs are None: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnone_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1188\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1189\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1190\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m   1191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors_out, (\u001b[38;5;28mdict\u001b[39m, TensorDictBase)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m   1192\u001b[39m     key \u001b[38;5;129;01min\u001b[39;00m tensors_out \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.out_keys\n\u001b[32m   1193\u001b[39m ):\n\u001b[32m   1194\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors_out, \u001b[38;5;28mdict\u001b[39m):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\common.py:1174\u001b[39m, in \u001b[36mTensorDictModule.forward\u001b[39m\u001b[34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[39m\n\u001b[32m   1165\u001b[39m     tensors = \u001b[38;5;28mtuple\u001b[39m(\n\u001b[32m   1166\u001b[39m         tensordict._get_tuple_maybe_non_tensor(\n\u001b[32m   1167\u001b[39m             _unravel_key_to_tuple(in_key),\n\u001b[32m   (...)\u001b[39m\u001b[32m   1171\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m in_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.in_keys\n\u001b[32m   1172\u001b[39m     )\n\u001b[32m   1173\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1174\u001b[39m     tensors_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1175\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tensors_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1176\u001b[39m         tensors_out = ()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\tensordict\\nn\\common.py:1133\u001b[39m, in \u001b[36mTensorDictModule._call_module\u001b[39m\u001b[34m(self, tensors, **kwargs)\u001b[39m\n\u001b[32m   1131\u001b[39m kwargs.update(\u001b[38;5;28mself\u001b[39m.method_kwargs)\n\u001b[32m   1132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1133\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1135\u001b[39m     out = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.module, \u001b[38;5;28mself\u001b[39m.method)(*tensors, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\werna\\miniconda3\\envs\\marl\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but got mat2 is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA_mm)"
          ]
        }
      ],
      "source": [
        "# --- imports ---\n",
        "import torch\n",
        "from torchrl.trainers import (\n",
        "    Trainer, BatchSubSampler, LogScalar, CountFramesLog,\n",
        "    LogValidationReward, OptimizerHook, TrainerHookBase\n",
        ")\n",
        "\n",
        "# CSVLogger импорт в TorchRL немного «гуляет» между версиями\n",
        "try:\n",
        "    from torchrl.record import CSVLogger\n",
        "except Exception:\n",
        "    from torchrl.record.loggers.csv import CSVLogger  # fallback\n",
        "\n",
        "# --- тут считаем, что у вас уже есть эти объекты, как в вашем цикле ---\n",
        "# env, actor, collector\n",
        "# loss_module: PPOLoss, выдаёт keys: \"loss_objective\", \"loss_critic\", \"loss_entropy\"\n",
        "# advantage_module: GAE(...) — пересчитывает \"advantage\" и \"value_target\"\n",
        "# optim (torch.optim.Optimizer), scheduler (torch.optim.lr_scheduler.*)\n",
        "# frames_per_batch, total_frames, device\n",
        "\n",
        "# --- гиперпараметры в духе вашего кода ---\n",
        "max_grad_norm = 1.0\n",
        "num_epochs = 10\n",
        "sub_batch_size = 64\n",
        "\n",
        "# сколько минибатчей на эпоху и всего оптимшагов на партию\n",
        "minibatches_per_epoch = frames_per_batch // sub_batch_size\n",
        "optim_steps_per_batch = num_epochs * minibatches_per_epoch\n",
        "\n",
        "# --- логгер (CSV; можно заменить на TensorBoard/W&B) ---\n",
        "logger = CSVLogger(exp_name=\"ppo_torchrl\", log_dir=\"logs\")\n",
        "\n",
        "# --- сам Trainer ---\n",
        "trainer = Trainer(\n",
        "    collector=collector,\n",
        "    total_frames=total_frames,\n",
        "    loss_module=loss_module,\n",
        "    optimizer=optim,\n",
        "    logger=logger,\n",
        "    optim_steps_per_batch=optim_steps_per_batch,\n",
        "    clip_grad_norm=True,   # клиппинг в тренере\n",
        "    clip_norm=max_grad_norm,\n",
        "    progress_bar=True,\n",
        "    frame_skip=1, \n",
        ")\n",
        "\n",
        "# --- 1) минибатчинг партии как в вашем RB.sample ---\n",
        "# берём переходы (sub_traj_len=0/−1 = полноразмерная временная ось, выборка по элементам)\n",
        "BatchSubSampler(batch_size=sub_batch_size, sub_traj_len=0).register(trainer)  # :contentReference[oaicite:1]{index=1}\n",
        "\n",
        "# --- 2) оптимизация по сумме ваших компонент потерь ---\n",
        "# Trainer сам вычислит loss через loss_module; OptimizerHook выберет компоненты и сделает backward/step.\n",
        "# OptimizerHook(optim, [\"loss_objective\", \"loss_critic\", \"loss_entropy\"]).register(trainer)  # :contentReference[oaicite:2]{index=2}\n",
        "\n",
        "# --- 3) пересчёт GAE перед каждой «эпохой» (как в вашем for _ in range(num_epochs): advantage_module(...)) ---\n",
        "class PPOEpochAdvantage(TrainerHookBase):\n",
        "    \"\"\"\n",
        "    Хук хранит текущую партию и:\n",
        "    - при получении партии (batch_process) один раз считает GAE;\n",
        "    - после каждого оптимшага (post_optim) считает шаги внутри партии и\n",
        "      каждые 'minibatches_per_epoch' пересчитывает GAE для следующей эпохи.\n",
        "    \"\"\"\n",
        "    def __init__(self, advantage_module, minibatches_per_epoch):\n",
        "        self.adv = advantage_module\n",
        "        self.mb_per_epoch = minibatches_per_epoch\n",
        "        self._batch = None\n",
        "        self._k = 0\n",
        "\n",
        "    def register(self, trainer, name=\"ppo_adv\"):\n",
        "        trainer.register_module(self, name)\n",
        "        trainer.register_op(\"batch_process\", self)   # получаем партию и первый расчёт GAE\n",
        "        trainer.register_op(\"post_optim\", self)      # счётчик минибатчей и пересчёт между эпохами\n",
        "\n",
        "    def __call__(self, *args):\n",
        "        # batch_process передаёт batch; post_optim — нет\n",
        "        if args:  # пришла партия\n",
        "            batch = args[0]\n",
        "            self._batch = batch\n",
        "            self._k = 0\n",
        "            self.adv(self._batch)     # первичный расчёт\n",
        "            return self._batch\n",
        "        else:      # пришёл post_optim\n",
        "            self._k += 1\n",
        "            if self._k % self.mb_per_epoch == 0:\n",
        "                # «рубеж эпохи»: обновили value — пересчитаем advantages на всей партии\n",
        "                self.adv(self._batch)\n",
        "\n",
        "PPOEpochAdvantage(advantage_module, minibatches_per_epoch).register(trainer)\n",
        "# идея «пересчитывать GAE перед каждой эпохой» описана и в туториале по PPO TorchRL. :contentReference[oaicite:3]{index=3}\n",
        "\n",
        "# --- 4) логирование (reward, шаги, lr) и прогресс ---\n",
        "# средняя тренинг-награда\n",
        "LogScalar(logname=\"train/reward\", log_pbar=True, reward_key=(\"next\", \"reward\")).register(trainer)  # :contentReference[oaicite:4]{index=4}\n",
        "# счётчик фреймов\n",
        "CountFramesLog(frame_skip=1, log_pbar=False).register(trainer)  # :contentReference[oaicite:5]{index=5}\n",
        "\n",
        "# максимальный step_count в партии (как у вас)\n",
        "class LogStepCount(TrainerHookBase):\n",
        "    def register(self, trainer, name=\"log_step_count\"):\n",
        "        trainer.register_module(self, name)\n",
        "        trainer.register_op(\"pre_steps_log\", self)\n",
        "    def __call__(self, batch):\n",
        "        key = (\"step_count\",)\n",
        "        if key not in batch.keys(True):\n",
        "            key = (\"next\", \"step_count\")\n",
        "        if key in batch.keys(True):\n",
        "            return {\"train/max_step_count\": batch.get(key).max().item(), \"log_pbar\": True}\n",
        "LogStepCount().register(trainer)\n",
        "\n",
        "# текущий LR (для прогресс-бара)\n",
        "class LogLR(TrainerHookBase):\n",
        "    def __init__(self, optimizer): self.opt = optimizer\n",
        "    def register(self, trainer, name=\"log_lr\"):\n",
        "        trainer.register_module(self, name)\n",
        "        trainer.register_op(\"post_steps_log\", self)\n",
        "    def __call__(self, batch):\n",
        "        return {\"train/lr\": self.opt.param_groups[0][\"lr\"], \"log_pbar\": True}\n",
        "LogLR(optim).register(trainer)\n",
        "\n",
        "# --- 5) scheduler.step() после каждой партии сбора (как у вас) ---\n",
        "class StepSchedulerEachBatch(TrainerHookBase):\n",
        "    def __init__(self, scheduler): self.sched = scheduler\n",
        "    def register(self, trainer, name=\"lr_sched\"):\n",
        "        trainer.register_module(self, name)\n",
        "        trainer.register_op(\"post_steps\", self)  # после оптимизаций на партии\n",
        "    def __call__(self): self.sched.step()\n",
        "StepSchedulerEachBatch(scheduler).register(trainer)\n",
        "\n",
        "# --- 6) валидация каждые 2 партии (≈ ваши eval каждые 2 i) ---\n",
        "# Хук считает «интервал» в оптимшагax, поэтому умножаем на optim_steps_per_batch.\n",
        "LogValidationReward(\n",
        "    record_interval=optim_steps_per_batch * 2,\n",
        "    record_frames=frames_per_batch,         # ~ несколько эпизодов; можно увеличить\n",
        "    policy_exploration=actor,               # актор в детерминированном режиме\n",
        "    environment=env,\n",
        "    log_keys=[(\"next\", \"reward\")],\n",
        "    out_keys={(\"next\", \"reward\"): \"eval/avg_reward\"},\n",
        "    log_pbar=True,\n",
        ").register(trainer)  # :contentReference[oaicite:6]{index=6}\n",
        "\n",
        "# --- поехали ---\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5efd5d7f",
      "metadata": {},
      "outputs": [],
      "source": [
        "asff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef61b650",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5900d0ef",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "464b11a5d86f44729f5072b975509583",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "eval – avg reward: 103.23108367919922, max episode lengh: 13\n",
            "eval – avg reward: 142.66787567138672, max episode lengh: 19\n",
            "eval – avg reward: 131.65445709228516, max episode lengh: 19\n",
            "eval – avg reward: 161.3946075439453, max episode lengh: 25\n",
            "eval – avg reward: 202.62415161132813, max episode lengh: 35\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "from tqdm.auto import tqdm\n",
        "from agentslab.runners.evals import eval_policy\n",
        "from collections import defaultdict\n",
        "\n",
        "logs = defaultdict(list)\n",
        "losses = []\n",
        "\n",
        "pbar = tqdm(total=total_frames, dynamic_ncols=True, leave=True)\n",
        "\n",
        "max_grad_norm = 1.0\n",
        "num_epochs = 10\n",
        "sub_batch_size = 64\n",
        "\n",
        "# Итерируемся по коллекторам, пока не наберём нужное число шагов\n",
        "for i, tensordict_data in enumerate(collector):\n",
        "    # Учимся на партии данных\n",
        "    for _ in range(num_epochs):\n",
        "        # Advantage для PPO пересчитываем на каждом проходе\n",
        "        advantage_module(tensordict_data)\n",
        "        data_view = tensordict_data.reshape(-1)\n",
        "        replay_buffer.extend(data_view.cpu())\n",
        "        for _ in range(frames_per_batch // sub_batch_size):\n",
        "            subdata = replay_buffer.sample(sub_batch_size)\n",
        "            loss_vals = loss_module(subdata.to(device))\n",
        "            loss_value = (\n",
        "                loss_vals[\"loss_objective\"] \n",
        "                + loss_vals[\"loss_critic\"] \n",
        "                + loss_vals[\"loss_entropy\"]\n",
        "            )\n",
        "            # Оптимизация\n",
        "            loss_value.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(loss_module.parameters(), max_grad_norm)\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "    scheduler.step()            # Шаг LR-планировщика\n",
        "\n",
        "    # Логируем метрики\n",
        "    logs[\"reward\"].append(tensordict_data[\"next\", \"reward\"].mean().item())\n",
        "    logs[\"step_count\"].append(tensordict_data[\"step_count\"].max().item())\n",
        "    logs[\"lr\"].append(optim.param_groups[0][\"lr\"])\n",
        "\n",
        "    # Оценка после каждых 2 партий (соответствует условию ниже)\n",
        "    if (i + 1) % 2 == 0:\n",
        "        eval_results = eval_policy(env, actor, episodes=5, progress=False)\n",
        "        # pbar.write не ломает отрисовку прогресс-бара\n",
        "        pbar.write(f\"eval – avg reward: {eval_results[\"return_mean\"]}, max episode lengh: {eval_results[\"max_episode_lengh\"]}\")\n",
        "\n",
        "    # Обновляем описание прогресс-бара\n",
        "    avg_reward_str = f\"avg reward={logs['reward'][-1]: 4.4f}\"\n",
        "    step_count_str = f\"max step count: {logs['step_count'][-1]}\"\n",
        "    lr_str = f\"lr: {logs['lr'][-1]: 4.4f}\"\n",
        "    \n",
        "    # корректное число фреймов в пачке\n",
        "    batch_frames = int(tensordict_data.get((\"next\", \"reward\")).numel())\n",
        "    # аккуратное обновление бара\n",
        "    inc = min(batch_frames, pbar.total - pbar.n)\n",
        "    if inc > 0:\n",
        "        pbar.update(inc)\n",
        "\n",
        "    pbar.set_description(\", \".join([avg_reward_str, step_count_str, lr_str]))\n",
        "\n",
        "# Гарантированно закрываем бар (важно для корректного вывода в ноутбуках)\n",
        "pbar.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd653412",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4447b00c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(logs[\"reward\"])\n",
        "plt.title(\"training rewards (average)\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(logs[\"step_count\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60add307",
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'EvalConfig' from 'agentslab.runners.evals' (C:\\Users\\ordevoir\\Documents\\GitHub\\AgentsLab\\src\\agentslab\\runners\\evals.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Cell 3: Конфигурирование trainer и запуск обучения\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magentslab\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunners\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PPOTrainer, PPOTrainerConfig\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magentslab\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunners\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EvalConfig, evaluate_policy\n\u001b[32m      5\u001b[39m trainer_cfg = PPOTrainerConfig(\n\u001b[32m      6\u001b[39m     frames_per_batch=\u001b[32m1024\u001b[39m,\n\u001b[32m      7\u001b[39m     total_frames=\u001b[32m20_480\u001b[39m,  \u001b[38;5;66;03m# демо; поднимайте до 1e6 для реальных результатов\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m     eval_every=\u001b[32m5\u001b[39m,\n\u001b[32m     19\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluator\u001b[39m():\n",
            "\u001b[31mImportError\u001b[39m: cannot import name 'EvalConfig' from 'agentslab.runners.evals' (C:\\Users\\ordevoir\\Documents\\GitHub\\AgentsLab\\src\\agentslab\\runners\\evals.py)"
          ]
        }
      ],
      "source": [
        "# Cell 3: Конфигурирование trainer и запуск обучения\n",
        "from agentslab.runners.trainers import PPOTrainer, PPOTrainerConfig\n",
        "from agentslab.runners.evals import EvalConfig, evaluate_policy\n",
        "\n",
        "trainer_cfg = PPOTrainerConfig(\n",
        "    frames_per_batch=1024,\n",
        "    total_frames=20_480,  # демо; поднимайте до 1e6 для реальных результатов\n",
        "    sub_batch_size=64,\n",
        "    num_epochs=10,\n",
        "    lr=3e-4,\n",
        "    max_grad_norm=1.0,\n",
        "    gamma=0.99,\n",
        "    lam=0.95,\n",
        "    clip_epsilon=0.2,\n",
        "    entropy_coef=1e-4,\n",
        "    seed=seed,\n",
        "    device=device,\n",
        "    eval_every=5,\n",
        ")\n",
        "\n",
        "def evaluator():\n",
        "    return evaluate_policy(env, actor, EvalConfig(steps=1000, device=device))\n",
        "\n",
        "trainer = PPOTrainer(trainer_cfg, env, actor, critic, run_dirs={'ckpt': run_ckpt_dir, 'logs': str(log_dir)}, logger=logger)\n",
        "trainer.train(evaluator=evaluator)\n",
        "\n",
        "# Сохранение чекпоинта\n",
        "ckpt_path = save_checkpoint(run_ckpt_dir, actor, critic, None, None, extra={'iter_done': trainer_cfg.total_frames // trainer_cfg.frames_per_batch})\n",
        "print('Saved to:', ckpt_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Конфигурирование и оценка модели\n",
        "from agentslab.runners.evals import EvalConfig, evaluate_policy\n",
        "eval_res = evaluate_policy(env, actor, EvalConfig(steps=1000, device=device))\n",
        "eval_res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Построение графиков по логам (matplotlib)\n",
        "import matplotlib.pyplot as plt\n",
        "csv_path = (log_dir / 'train_log.csv')\n",
        "print('CSV:', csv_path)\n",
        "from agentslab.utils.curves import plot_training_curves\n",
        "plot_training_curves(str(csv_path))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Запуск среды с выбранным render_mode\n",
        "from torchrl.envs.utils import ExplorationType, set_exploration_type\n",
        "from tqdm import tqdm\n",
        "\n",
        "if env_cfg.render_mode is None:\n",
        "    print('Пересоздаём env с render_mode=\"human\" для визуализации...')\n",
        "    env_cfg_vis = GymEnvConfig(env_id=env_cfg.env_id, render_mode='human', device=device, seed=seed)\n",
        "    env_vis = make_gym_env(env_cfg_vis)\n",
        "else:\n",
        "    env_vis = env\n",
        "\n",
        "with torch.no_grad():\n",
        "    with set_exploration_type(ExplorationType.DETERMINISTIC):\n",
        "        td = env_vis.reset()\n",
        "        for _ in tqdm(range(500)):\n",
        "            td = actor(td)\n",
        "            td = env_vis.step(td)\n",
        "            td = td.get('next')\n",
        "\n",
        "env_vis.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Восстановление модели из чекпоинта\n",
        "from agentslab.utils.checkpointers import load_checkpoint\n",
        "loaded = load_checkpoint(str(Path(run_ckpt_dir) / 'checkpoint.pt'), actor, critic)\n",
        "print('Loaded extra:', loaded)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "marl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
